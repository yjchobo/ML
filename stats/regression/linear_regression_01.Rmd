---
title: "Linear Regression - Airbnb data"
output:
  html_document:
    df_print: paged
---
```{r echo=FALSE}
path = "/Users/young.cho/Documents/portfolio/portfolio/datasets/"
path2 = "/Users/young.cho/Documents/portfolio/portfolio/media/"
```
***
Load up Libraries

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(GGally)
```

## Airbnb Data
```{r}
airbnb_df = read.csv(paste(path,"airbnb_data.csv",sep=""))
knitr::kable(head(airbnb_df, 4), "pandoc")
```

#### Let's fit a multiple linear regression model using price as the response variable and all others as predictor variables (Note: remove ‘id’ columns). We will check which variables are statistically significant in determining the price.

```{r}
#Remove all 'id' columns first
airbnb_df_no_ID = select(airbnb_df, -contains("id"))
knitr::kable(head(airbnb_df_no_ID, 4), "pandoc")
```

```{r}
#Create Multiple Linear Regression Model
#Not mentioned in the question, but apparently this df only contains one city "Asheville"
#We will not include that in the model as it is not useful
air_MLM = lm(price ~ room_type + reviews + overall_satisfaction + accommodates + bedrooms, data=airbnb_df_no_ID)

#Display model output
summary(air_MLM)
```

As we can see from the above summary output from the model, the variables that are statistically significant in determining price are: __“overall_satisfaction”__, __“accommodates”__ and __“bedrooms”__. This is assuming an alpha value of .05.

### How would we interpret coefficients for predictors?
- Ex.1) A shared room is associated with a decrease of $76.67 in price on average holding all else constant.
- Ex.2) A one unit increase in bedrooms (so each additional bedroom) is associated with an increase of $85.65 in price on average holding all else constant.

#### Let's take an example and predict the price using the above multiple linear model. How about a listing with 1 bedroom that can accomodate 2 people, with total of 70 reviews with mean rating of 4 that is a private room. What does our model estimate its rental price should be?

```{r}
pred_data = data.frame(bedrooms=1, accommodates=2, reviews=70, overall_satisfaction=4, room_type='Private room')
#Prediction using Prediction interval
air_MLM_pred = predict(air_MLM, pred_data, interval = "predict")
air_MLM_pred
```

As we can see from the output of the prediction above, with the following factor values: bedrooms = 1, accommodates = 2, reviews = 70, overall_satisfaction = 4, and room_type = ‘Private room’ the predicted price is $66.

As an aside, when doing predictions, I will include both prediction and confidence intervals so we can compere the lower and upper bounds.

> For additional edification on which you should use: According to ISLR we should use a prediction interval if we wish to predict an individual response and use a confidence interval if we wish to predict the average response. Also, this [article](http://www.sthda.com/english/articles/40-regression-analysis/166-predict-in-r-model-predictions-and-confidence-intervals/) sums it up nicely. From the article, “A prediction interval reflects the uncertainty around a single value, while a confidence interval reflects the uncertainty around the mean prediction values. Thus, a prediction interval will be generally much wider than a confidence interval for the same value.”

Checkout this [video](https://www.youtube.com/watch?feature=player_embedded&v=o0UESA3UZss) for more context on confidence interval vs. prediction interval: ![](/Users/young.cho/Documents/portfolio/portfolio/media/ci_vs_pi.jpg) 

#### Next let's identify outliers using Cook’s distance approach.

Identify outliers using Cook’s distance approach. Remove points having Cook’s distance > 1. Rerun the model after the removal of these points and print the summary.

```{r}
#Find leverage points using the Residuals vs Leverage plot
#Cook's distance > 1 
plot(air_MLM, which = 5)
```

```{r}
#Remove identified leverage points
airbnb_df_no_ID_clean = airbnb_df_no_ID[-c(94, 95),]

#Rerun the model after removing points where Cook's distance is > 1
air_MLM_clean = lm(price ~ room_type + reviews + overall_satisfaction + accommodates + bedrooms, data=airbnb_df_no_ID_clean)
summary(air_MLM_clean)
```

Isn't this facinating? The summary output seems to make way more logical sense now. After removing records 94 and 95, where Cook’s distance > 1, the only X variable that doesn’t look significant is now reviews. Assuming an alpha of .05, all other predictor variables look significant to the model. We can also see from the newly plotted Residuals vs Leverage plot that no values exceed Cook’s distance > 1.

And next let’s run a new prediction model using the cleaned data set.

```{r}
#Predicting using confidence interval
air_MLM_pred_clean = predict(air_MLM_clean, pred_data, interval = "confidence")
air_MLM_pred_clean
```

```{r}
#predicting using Prediction interval
air_MLM_pred_clean = predict(air_MLM_clean, pred_data, interval = "prediction")
air_MLM_pred_clean
```

Compared to our first prediction, the new prediction has much narrower lower and upper bands with a predicted value of $71.